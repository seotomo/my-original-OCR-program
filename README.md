# 自作OCRプログラムの作成

## 目的
既存のOCRソフトは数多くあるが、日本語の文字認識は非常に難しいと言われている。理由として①ひらがな・カタカナに似た文字が多い、②「け」や「は」など独立した複数の画から構成される文字が多い、などが挙げられる。特に手書き文字の認識では精度が低いと言われる。そこで手書き文字に対応したOCRを自作し、既存のものと比べどこまで精度が出せるかを試してみた。

## 対応文書
1.	スキャンされた手書き文字
2.	スキャンされた印刷文字   
      の2種類。現状**横書き**のみ対応している。
      
  
<img src="/images/ocr_images/スキャンされた手書き文字.jpg" width = "500"> <img src="/images/ocr_images/スキャンされた印刷文字.jpg" width = "500">  
　　　　　　　　　__スキャンされた手書き文字__　　　　　　　　　　　　　　　　　　　　__スキャンされた印刷文字__    
<br>  
<br> 
 
## OCRプログラムファイル名：/ocr/my_ocr.py
処理は大きく分けて①文字抽出、②文字予測の2つに分かれている。

## ①文字抽出
### 1. 前処理  

**1)ファイル読み込み**

<img src="/images/ocr_images/ファイル読み込み.jpg" width = "700">  
文書の形式のみ手動で選択する。  
<br>  
<br>  
<br>

**2)直線除去**  
<img src="/images/ocr_images/直線除去.jpg" width = "500">  
**RemoveLinesFromImage関数**により直線除去を行う。
処理内容はソーベルフィルタにより縦もしくは横方向にエッジ強調を行い、作成したエッジ強調画像に対しラベリング処理をかけ、ラベルの縦横比が15以上であれば線と判定し、除去を行う。この処理は縦方向・横方向に2回かけ、両方向の直線に対応させる。

<img src="/images/ocr_images/直線除去_前.jpg" width = "300">  <img src="/images/ocr_images/直線除去_ソーベルフィルタ.jpg" width = "300">　 <img src="/images/ocr_images/直線除去_後.jpg" width = "300">  
　　　　　　　　__直線除去前__　　　　　　　　　　__ソーベルフィルタ（上下方向）__　　　　　　　　　　__直線除去後__      
<br>  
<br> 
  
**3)ノイズ除去**  
<img src="/images/ocr_images/ノイズ除去.jpg" width = "400">  
この後行う文字抽出に向け、**RemoveNoiseFromImage関数**では2値化等のノイズ除去処理を行う。  

<img src="/images/ocr_images/ノイズ除去_前.jpg" width = "400">  <img src="/images/ocr_images/ノイズ除去_後.jpg" width = "400">  
　　　　　　　　　　__ノイズ除去前__　　　　　　　　　　　　     　　　　__ノイズ除去後__  
<br>  
<br>
  
### 2.行認識
文字列の行を認識する。  
  
**1)文字サイズの取得・図形の除去**  
<img src="/images/ocr_images/文字サイズの取得・図形の除去.jpg" width = "900">  
**GetCharSize関数**により、ノイズ除去した画像に対しラベリング処理をかけ、得られた１つ１つのラベル情報(面積・高さ・幅)の中央値を平均的な文字の面積・高さ・幅の情報として取得する。その後、**RemoveFigure関数**を用いて得られた文字サイズの情報からラベルサイズが大きすぎるものは図形と判定し、除去を行う。
<br>  
<br>

**2)文字列の位置を認識**  
<img src="/images/ocr_images/文字列の切り出し.jpg" width = "00">  
**FindLinePeak関数**では文書の左右方向にピクセル値を合計したピクセル値カーブを作成し、そのピークの高さから行の位置を判定する。
**ConnectCharsOnLine関数**では判定した行の高さに対し、最も左側にある文字と最も右側にある文字をラベルの有無で判定する。文字かどうかはラベルの大きさがある一定を超えているかで判定する。その後、2文字間をつなぐ線を描画し、1つのその行全体が一つのラベルとして処理できるようにする。
**DetectLines関数**ではConnectCharsOnLine関数で結合した行全体に対し外接矩形を求め、矩形内が1行となるようにする。文字列全体が斜めになっている場合に対応するため、外接矩形は回転を考慮し、openCVのminAreaRect関数を用いる。複数の矩形が重なっている場合は矩形同士の重なった面積の割合から、合わせて1つの行と認識するか、異なる行と認識するかを判定する。  

<img src="/images/ocr_images/文字列の切り出し_1.jpg" width = "300">  <img src="/images/ocr_images/文字列の切り出し_2.jpg" width = "300">　 <img src="/images/ocr_images/文字列の切り出し_3.jpg" width = "300">  
　　　　　　　__行の位置判定__　　　　　　　　　　　　__行全体の結合__  　　　　 　　　     　　　　　　    __矩形の設置__
<br>  
<br>


**3)行の成形**   
<img src="/images/ocr_images/行の成形.jpg" width = "600">  
**ProcessingLines関数**では外接矩形の傾きを補正するため、矩形の高さ、幅はそのままで射影変換を行い、行全体を水平に変換する。
**TransformLinesList関数**ではそれぞれの行の左上のy軸ピクセル値を連番に変換し、この後の文字抽出で処理がしやすくなるようにする。  
<br>  
<br>

### 3.文字の抽出  
文字列から1文字ずつ取り出す。  

**1)文字の位置を認識**  
<img src="/images/ocr_images/文字の抽出.jpg" width = "600">  
**DetectChars関数**では抽出したそれぞれの行に対し処理をかけ、さらに1文字ずつ抽出している。まず1つの行に対し上下方向にピクセル値を合計したピクセル値カーブを作成し、ピクセル合計値が0から1以上に変化している場所は文字の始まりの位置、1以上から０に変化している場所は文字の終わりの位置として認識する。その後文字の幅が狭すぎる場合は両サイドの文字との間や両サイドの文字の幅を確認し、1つの文字として結合するかを判定、結合を行う。また、文字の幅が広すぎる場合は複数の文字がつながっていると判定し、ピクセルカーブのピクセル合計値が小さな位置で分離を行い、文字同士を切り離す。文字結合や分離に用いたパラメータは文書の形式によって変えている。（規則正しく文字が並ぶ印刷文字と文字の大きさにばらつきがある手書き文字で同一のパラメータを用いるのは不適と考えたため。）最終的に抽出した1文字の枠内に対し、学習したAIモデルを適応するため、DetectChars関数内では**PreprocessingForLearning関数**を用いて文字予測の前処理を行っている。  
<br>
<img src="/images/ocr_images/抽出した文字(例).jpg" width = "600">  
　　　　　　　　　　　　　　　　__抽出した文字__  
             
<br>  
<br>

## ②文字予測
**1)モデルの読み込み**  
<img src="/images/ocr_images/モデルの読み込み.jpg" width = "600">  
学習済みモデルのファイルと文字とラベル番号の対応関係を記録した.npyファイルを読み込む。（詳しくは学習の項を参照）
<br>  
<br>

**2)文字予測**  
<img src="/images/ocr_images/文字予測.jpg" width = "450">   
DetectChars関数から得られた1文字1文字の画像データを学習済みモデルに渡し、文字予測を行い、テキストファイルとして書き起こす。行の高さが異なる場合は改行される。
<br>  
<br>

## 最終的な精度
<img src="/images/ocr_images/最終結果_手書き.jpg" width = "400">　<img src="/images/ocr_images/最終結果_印刷.jpg" width = "550">  
　　　　　　　__テキスト化後（手書き文字）__　　　　　　　　　　　     　　　　__テキスト化後（印刷文字）__  
<br>

最終的な精度は**8割**ほどの精度であった。やはり**ナ**と**十**や、 **C** と **(** など似た文字での認識ミスが多かった。このミスについてはAIでの予測後に文脈から文字を訂正する処理をかけることで対応可能だと考えられる。また、カタカナの濁音がデータベースになかったため、現状対応できていないことも大きい。文字の抽出過程でも１文字を２つに分けて抽出している場合もあり、さらなる改善の余地があると感じた。
<br>  
<br>
















 
 
 
